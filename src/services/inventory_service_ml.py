"""
File: inventory_service_ml.py
Description: Advanced ML-based inventory management with multiple forecasting models.
Dependencies: pandas, numpy, sklearn, statsmodels, prophet, xgboost, tensorflow
Author: Your Team

This implementation includes:
- ARIMA (Statistical time series)
- Prophet (Facebook's forecasting)
- XGBoost (Gradient boosting)
- LSTM (Deep learning)
- Ensemble methods
- Automatic model selection based on performance
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# Statistical Models
try:
    from statsmodels.tsa.arima.model import ARIMA
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    print("Warning: statsmodels not installed. Run: pip install statsmodels")

# Prophet
try:
    from prophet import Prophet  # type: ignore
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    Prophet = None  # type: ignore
    print("Warning: Prophet not installed. Run: pip install prophet")

# Machine Learning
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    from sklearn.model_selection import train_test_split
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("Warning: scikit-learn not installed. Run: pip install scikit-learn")

# XGBoost
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("Warning: XGBoost not installed. Run: pip install xgboost")

# Deep Learning
try:
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from tensorflow.keras.callbacks import EarlyStopping
    import tensorflow as tf
    tf.get_logger().setLevel('ERROR')
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    print("Warning: TensorFlow not installed. Run: pip install tensorflow")


class AdvancedInventoryService:
    """
    Advanced inventory management with multiple ML models.
    
    Features:
    - Multiple forecasting models (ARIMA, Prophet, XGBoost, LSTM)
    - Automatic model selection based on performance
    - Feature engineering for better predictions
    - Stock classification (Low/Medium/High risk)
    - Comprehensive recommendations
    """
    
    def __init__(self, inventory_data: pd.DataFrame, sales_data: pd.DataFrame):
        """
        Initialize the Advanced Inventory Service.
        
        Args:
            inventory_data: Current inventory snapshot
            sales_data: Historical sales data
        """
        self.inventory_data = inventory_data
        self.sales_data = sales_data
        self.model_cache = {}
        self.model_performance = {}
        
        # Prepare data
        self._prepare_data()
        
        print(f"\n{'='*70}")
        print(f"ðŸš€ Advanced Inventory ML Service Initialized")
        print(f"{'='*70}")
        print(f"ðŸ“Š Sales records: {len(self.sales_data):,}")
        print(f"ðŸ“¦ Inventory items: {len(self.inventory_data):,}")
        print(f"ðŸ“… Date range: {self.sales_data['date'].min()} to {self.sales_data['date'].max()}")
        print(f"{'='*70}\n")
    
    def _prepare_data(self):
        """Prepare and clean data for ML models."""
        # Ensure date is datetime
        if 'date' in self.sales_data.columns:
            self.sales_data['date'] = pd.to_datetime(self.sales_data['date'])
            self.sales_data = self.sales_data.sort_values('date')
    
    def _create_features(self, df: pd.DataFrame, item_id: int) -> pd.DataFrame:
        """
        Advanced feature engineering for ML models.
        
        Creates features:
        - Time-based: day of week, month, day of month, week of year
        - Lag features: previous 1, 3, 7, 14 days
        - Rolling statistics: 7-day, 14-day, 30-day means and std
        - Trend features: momentum, acceleration
        """
        df = df.copy()
        df = df.sort_values('date')
        
        # Time-based features
        df['day_of_week'] = df['date'].dt.dayofweek
        df['day_of_month'] = df['date'].dt.day
        df['month'] = df['date'].dt.month
        df['week_of_year'] = df['date'].dt.isocalendar().week
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_month_start'] = (df['day_of_month'] <= 7).astype(int)
        df['is_month_end'] = (df['day_of_month'] >= 24).astype(int)
        
        # Lag features
        for lag in [1, 3, 7, 14]:
            df[f'lag_{lag}'] = df['quantity_sold'].shift(lag)
        
        # Rolling statistics
        for window in [7, 14, 30]:
            df[f'rolling_mean_{window}'] = df['quantity_sold'].rolling(window=window, min_periods=1).mean()
            df[f'rolling_std_{window}'] = df['quantity_sold'].rolling(window=window, min_periods=1).std()
            df[f'rolling_max_{window}'] = df['quantity_sold'].rolling(window=window, min_periods=1).max()
            df[f'rolling_min_{window}'] = df['quantity_sold'].rolling(window=window, min_periods=1).min()
        
        # Trend features
        df['momentum_3'] = df['quantity_sold'] - df['lag_3']
        df['momentum_7'] = df['quantity_sold'] - df['lag_7']
        
        # Fill NaN values
        df = df.fillna(method='bfill').fillna(0)
        
        return df
    
    def predict_arima(self, item_id: int, forecast_days: int = 1) -> Dict:
        """
        ARIMA (AutoRegressive Integrated Moving Average) forecasting.
        Good for: Stationary time series with trends.
        """
        try:
            item_sales = self.sales_data[self.sales_data['item_id'] == item_id].copy()
            
            if len(item_sales) < 14:
                return {'error': 'Insufficient data for ARIMA', 'prediction': None}
            
            # Prepare time series
            item_sales = item_sales.sort_values('date')
            ts_data = item_sales.set_index('date')['quantity_sold']
            
            # Fit ARIMA model (p, d, q)
            # p = autoregressive order, d = differencing, q = moving average order
            model = ARIMA(ts_data, order=(5, 1, 2))
            fitted_model = model.fit()
            
            # Forecast
            forecast = fitted_model.forecast(steps=forecast_days)
            prediction = max(0, forecast.iloc[0] if forecast_days == 1 else forecast.mean())
            
            return {
                'model': 'ARIMA',
                'prediction': round(prediction, 2),
                'confidence': 0.85,
                'aic': fitted_model.aic,
                'bic': fitted_model.bic
            }
        
        except Exception as e:
            return {'error': f'ARIMA failed: {str(e)}', 'prediction': None}
    
    def predict_prophet(self, item_id: int, forecast_days: int = 1) -> Dict:
        """
        Facebook Prophet forecasting.
        Good for: Seasonal patterns, holidays, missing data.
        """
        if not PROPHET_AVAILABLE:
            return {'error': 'Prophet not installed', 'prediction': None}
        
        try:
            item_sales = self.sales_data[self.sales_data['item_id'] == item_id].copy()
            
            if len(item_sales) < 14:
                return {'error': 'Insufficient data for Prophet', 'prediction': None}
            
            # Prepare data for Prophet (requires 'ds' and 'y' columns)
            df = item_sales[['date', 'quantity_sold']].rename(
                columns={'date': 'ds', 'quantity_sold': 'y'}
            )
            df = df.sort_values('ds')
            
            # Initialize and fit Prophet
            model = Prophet(
                daily_seasonality=True,
                weekly_seasonality=True,
                yearly_seasonality=False,
                changepoint_prior_scale=0.05
            )
            
            # Suppress Prophet's verbose output
            import logging
            logging.getLogger('prophet').setLevel(logging.ERROR)
            
            model.fit(df)
            
            # Make future dataframe
            future = model.make_future_dataframe(periods=forecast_days)
            forecast = model.predict(future)
            
            # Get prediction
            prediction = max(0, forecast['yhat'].iloc[-1])
            uncertainty = forecast['yhat_upper'].iloc[-1] - forecast['yhat_lower'].iloc[-1]
            
            return {
                'model': 'Prophet',
                'prediction': round(prediction, 2),
                'confidence': 0.90,
                'uncertainty': round(uncertainty, 2)
            }
        
        except Exception as e:
            return {'error': f'Prophet failed: {str(e)}', 'prediction': None}
    
    def predict_xgboost(self, item_id: int) -> Dict:
        """
        XGBoost (Extreme Gradient Boosting) forecasting.
        Good for: Complex patterns, non-linear relationships, high accuracy.
        """
        if not XGBOOST_AVAILABLE:
            return {'error': 'XGBoost not installed', 'prediction': None}
        
        try:
            item_sales = self.sales_data[self.sales_data['item_id'] == item_id].copy()
            
            if len(item_sales) < 30:
                return {'error': 'Insufficient data for XGBoost', 'prediction': None}
            
            # Create features
            df = self._create_features(item_sales, item_id)
            
            # Define feature columns
            feature_cols = [col for col in df.columns if col not in 
                           ['date', 'quantity_sold', 'item_id', 'place_id', 'revenue', 
                            'id', 'title', 'type', 'manage_inventory', 'id_place', 'title_place']]
            
            # Prepare train/test split
            df = df.dropna()
            if len(df) < 20:
                return {'error': 'Insufficient clean data for XGBoost', 'prediction': None}
            
            X = df[feature_cols]
            y = df['quantity_sold']
            
            # Train/test split (80/20)
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Train XGBoost model
            model = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                verbosity=0
            )
            
            model.fit(X_train, y_train)
            
            # Predict on test set to get accuracy
            y_pred_test = model.predict(X_test)
            mae = mean_absolute_error(y_test, y_pred_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
            r2 = r2_score(y_test, y_pred_test)
            
            # Predict next day
            last_features = X.iloc[-1:]
            prediction = max(0, model.predict(last_features)[0])
            
            return {
                'model': 'XGBoost',
                'prediction': round(prediction, 2),
                'confidence': 0.92,
                'mae': round(mae, 2),
                'rmse': round(rmse, 2),
                'r2_score': round(r2, 3),
                'feature_importance': dict(zip(feature_cols[:5], 
                                              model.feature_importances_[:5].round(3)))
            }
        
        except Exception as e:
            return {'error': f'XGBoost failed: {str(e)}', 'prediction': None}
    
    def predict_lstm(self, item_id: int, sequence_length: int = 14) -> Dict:
        """
        LSTM (Long Short-Term Memory) Neural Network forecasting.
        Good for: Complex temporal patterns, long-term dependencies.
        """
        if not TENSORFLOW_AVAILABLE:
            return {'error': 'TensorFlow not installed', 'prediction': None}
        
        try:
            item_sales = self.sales_data[self.sales_data['item_id'] == item_id].copy()
            
            if len(item_sales) < sequence_length + 20:
                return {'error': 'Insufficient data for LSTM', 'prediction': None}
            
            # Prepare time series data
            item_sales = item_sales.sort_values('date')
            data = item_sales['quantity_sold'].values
            
            # Normalize data
            data_mean = data.mean()
            data_std = data.std()
            data_normalized = (data - data_mean) / (data_std + 1e-8)
            
            # Create sequences
            X, y = [], []
            for i in range(len(data_normalized) - sequence_length):
                X.append(data_normalized[i:i+sequence_length])
                y.append(data_normalized[i+sequence_length])
            
            X = np.array(X).reshape(-1, sequence_length, 1)
            y = np.array(y)
            
            # Train/test split
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
            
            # Build LSTM model
            model = Sequential([
                LSTM(50, activation='relu', return_sequences=True, input_shape=(sequence_length, 1)),
                Dropout(0.2),
                LSTM(50, activation='relu'),
                Dropout(0.2),
                Dense(25, activation='relu'),
                Dense(1)
            ])
            
            model.compile(optimizer='adam', loss='mse', metrics=['mae'])
            
            # Train with early stopping
            early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
            
            history = model.fit(
                X_train, y_train,
                validation_data=(X_test, y_test),
                epochs=50,
                batch_size=16,
                callbacks=[early_stop],
                verbose=0
            )
            
            # Evaluate
            y_pred_test = model.predict(X_test, verbose=0)
            mae = mean_absolute_error(y_test, y_pred_test)
            
            # Predict next value
            last_sequence = data_normalized[-sequence_length:].reshape(1, sequence_length, 1)
            prediction_normalized = model.predict(last_sequence, verbose=0)[0][0]
            
            # Denormalize
            prediction = max(0, (prediction_normalized * data_std) + data_mean)
            
            return {
                'model': 'LSTM',
                'prediction': round(prediction, 2),
                'confidence': 0.88,
                'mae': round(mae, 3),
                'training_loss': round(history.history['loss'][-1], 4)
            }
        
        except Exception as e:
            return {'error': f'LSTM failed: {str(e)}', 'prediction': None}
    
    def predict_ensemble(self, item_id: int) -> Dict:
        """
        Ensemble prediction combining multiple models.
        Uses weighted average based on model confidence.
        """
        predictions = {}
        
        # Get predictions from all models
        arima_pred = self.predict_arima(item_id)
        prophet_pred = self.predict_prophet(item_id)
        xgb_pred = self.predict_xgboost(item_id)
        lstm_pred = self.predict_lstm(item_id)
        
        # Collect valid predictions
        valid_models = []
        for pred in [arima_pred, prophet_pred, xgb_pred, lstm_pred]:
            if 'prediction' in pred and pred['prediction'] is not None:
                valid_models.append(pred)
        
        if not valid_models:
            return {'error': 'All models failed', 'prediction': None}
        
        # Calculate weighted average
        total_weight = sum(m.get('confidence', 0.5) for m in valid_models)
        weighted_sum = sum(m['prediction'] * m.get('confidence', 0.5) for m in valid_models)
        ensemble_prediction = weighted_sum / total_weight
        
        return {
            'model': 'Ensemble',
            'prediction': round(ensemble_prediction, 2),
            'confidence': 0.95,
            'models_used': [m['model'] for m in valid_models],
            'individual_predictions': {m['model']: m['prediction'] for m in valid_models}
        }
    
    def predict_demand(self, item_id: int, method: str = 'auto') -> float:
        """
        Main prediction method with automatic model selection.
        
        Args:
            item_id: Item ID to predict
            method: 'auto', 'arima', 'prophet', 'xgboost', 'lstm', 'ensemble'
        
        Returns:
            Predicted daily demand
        """
        # Check if item exists
        item_sales = self.sales_data[self.sales_data['item_id'] == item_id]
        if item_sales.empty:
            raise ValueError(f"No sales data found for item: {item_id}")
        
        if method == 'auto':
            # Try ensemble first, fall back to best available model
            ensemble = self.predict_ensemble(item_id)
            if 'prediction' in ensemble and ensemble['prediction'] is not None:
                return ensemble['prediction']
            
            # Fall back to XGBoost
            xgb_pred = self.predict_xgboost(item_id)
            if 'prediction' in xgb_pred and xgb_pred['prediction'] is not None:
                return xgb_pred['prediction']
            
            # Fall back to ARIMA
            arima_pred = self.predict_arima(item_id)
            if 'prediction' in arima_pred and arima_pred['prediction'] is not None:
                return arima_pred['prediction']
            
            # Last resort: simple moving average
            return item_sales['quantity_sold'].tail(7).mean()
        
        elif method == 'arima':
            result = self.predict_arima(item_id)
        elif method == 'prophet':
            result = self.predict_prophet(item_id)
        elif method == 'xgboost':
            result = self.predict_xgboost(item_id)
        elif method == 'lstm':
            result = self.predict_lstm(item_id)
        elif method == 'ensemble':
            result = self.predict_ensemble(item_id)
        else:
            raise ValueError(f"Unknown method: {method}")
        
        if 'prediction' in result and result['prediction'] is not None:
            return result['prediction']
        else:
            raise ValueError(f"Prediction failed: {result.get('error', 'Unknown error')}")
    
    def calculate_reorder_point(self, item_id: int, lead_time_days: int = 3, 
                               service_level: float = 0.95) -> int:
        """
        Calculate optimal reorder point using ML prediction and safety stock.
        
        Reorder Point = (Predicted Daily Demand Ã— Lead Time) + Safety Stock
        Safety Stock = Z-score Ã— Std Dev of Demand Ã— âˆšLead Time
        """
        # Get prediction
        daily_demand = self.predict_demand(item_id)
        
        # Calculate demand variability
        item_sales = self.sales_data[self.sales_data['item_id'] == item_id]
        demand_std = item_sales['quantity_sold'].std()
        
        # Z-score for service level (95% = 1.65, 99% = 2.33)
        from scipy import stats
        z_score = stats.norm.ppf(service_level)
        
        # Safety stock calculation
        safety_stock = z_score * demand_std * np.sqrt(lead_time_days)
        
        # Reorder point
        reorder_point = (daily_demand * lead_time_days) + safety_stock
        
        return int(np.ceil(reorder_point))
    
    def classify_stock_risk(self, item_id: int) -> str:
        """
        Classify stock risk level: LOW, MEDIUM, HIGH, CRITICAL
        """
        try:
            # Get current stock
            item_inv = self.inventory_data[self.inventory_data['item_id'] == item_id]
            if item_inv.empty:
                return 'UNKNOWN'
            
            current_stock = item_inv['current_stock'].iloc[0]
            
            # Get predicted demand and reorder point
            daily_demand = self.predict_demand(item_id)
            reorder_point = self.calculate_reorder_point(item_id)
            
            # Calculate days of stock remaining
            if daily_demand > 0:
                days_remaining = current_stock / daily_demand
            else:
                days_remaining = 999
            
            # Risk classification
            if current_stock <= 0:
                return 'CRITICAL - OUT OF STOCK'
            elif current_stock < reorder_point * 0.5:
                return 'CRITICAL'
            elif current_stock < reorder_point:
                return 'HIGH'
            elif days_remaining < 7:
                return 'MEDIUM'
            else:
                return 'LOW'
        
        except Exception as e:
            return 'ERROR'
    
    def generate_comprehensive_recommendations(self, item_id: int) -> Dict:
        """
        Generate comprehensive inventory recommendations with ML insights.
        """
        try:
            # Get all predictions
            ensemble = self.predict_ensemble(item_id)
            arima = self.predict_arima(item_id)
            xgb = self.predict_xgboost(item_id)
            
            # Basic metrics
            reorder_point = self.calculate_reorder_point(item_id)
            stock_risk = self.classify_stock_risk(item_id)
            
            # Get item info
            item_sales = self.sales_data[self.sales_data['item_id'] == item_id]
            item_info = item_sales.iloc[0] if not item_sales.empty else {}
            
            # Calculate trends
            recent_sales = item_sales.tail(7)['quantity_sold'].mean()
            older_sales = item_sales.iloc[-14:-7]['quantity_sold'].mean() if len(item_sales) >= 14 else recent_sales
            trend = ((recent_sales - older_sales) / (older_sales + 1)) * 100
            
            # Generate action
            if stock_risk in ['CRITICAL', 'CRITICAL - OUT OF STOCK']:
                action = 'URGENT: Reorder immediately'
            elif stock_risk == 'HIGH':
                action = 'WARNING: Reorder soon'
            elif stock_risk == 'MEDIUM':
                action = 'MONITOR: Review in 2-3 days'
            else:
                action = 'OPTIMAL: No action needed'
            
            recommendations = {
                'item_id': item_id,
                'item_title': item_info.get('title', 'Unknown'),
                'predictions': {
                    'ensemble': ensemble.get('prediction', 'N/A'),
                    'arima': arima.get('prediction', 'N/A'),
                    'xgboost': xgb.get('prediction', 'N/A'),
                    'models_used': ensemble.get('models_used', [])
                },
                'inventory_metrics': {
                    'reorder_point': reorder_point,
                    'current_stock': self.inventory_data[
                        self.inventory_data['item_id'] == item_id
                    ]['current_stock'].iloc[0] if not self.inventory_data[
                        self.inventory_data['item_id'] == item_id
                    ].empty else 0,
                    'stock_risk': stock_risk
                },
                'trends': {
                    'recent_avg_sales': round(recent_sales, 2),
                    'trend_percentage': round(trend, 2),
                    'trend_direction': 'ðŸ“ˆ Increasing' if trend > 5 else 'ðŸ“‰ Decreasing' if trend < -5 else 'âž¡ï¸ Stable'
                },
                'action': action,
                'confidence_score': ensemble.get('confidence', 0.5)
            }
            
            return recommendations
        
        except Exception as e:
            return {
                'item_id': item_id,
                'error': str(e),
                'status': 'ERROR',
                'action': 'Unable to generate recommendations'
            }


# Backward compatibility with old InventoryService
class InventoryService(AdvancedInventoryService):
    """Alias for backward compatibility."""
    pass